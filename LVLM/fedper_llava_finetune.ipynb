{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PcrysXFVbdR"
   },
   "source": [
    "# Federated Learning with LLaVA-NeXT-Video\n",
    "**Goal**: Fine-tune a violence detection model across decentralized clients without sharing raw video data.\n",
    "\n",
    "## Key Features:\n",
    "- Uses **QLoRA** (4-bit quantization) for efficient federated training.\n",
    "- **Flower** framework for federated averaging.\n",
    "- Simulates 4 clients + 1 server in one notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3lsOwzkYlXk",
    "outputId": "a09ce2d6-efd8-4eb3-ee13-32aed0374c82"
   },
   "outputs": [],
   "source": [
    "# === Core Libraries ===\n",
    "!pip install -q kagglehub\n",
    "!pip install -q opencv-python-headless\n",
    "!pip install -q av\n",
    "!pip install -q decord\n",
    "!pip install -q torchvision\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q seaborn\n",
    "!pip install -q tensorboard\n",
    "\n",
    "# === Hugging Face & Model Training ===\n",
    "!pip install -q transformers datasets sentencepiece accelerate bitsandbytes peft trl\n",
    "\n",
    "# === Federated Learning ===\n",
    "!pip install -q flwr flwr-datasets flwr[simulation]\n",
    "\n",
    "# === Configuration & Logging ===\n",
    "!pip install -q omegaconf hydra-core\n",
    "\n",
    "# === Energy Tracking ===\n",
    "!pip install -q codecarbon\n",
    "\n",
    "!pip install -q ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqljcnDhUlAe",
    "outputId": "a0b4990f-578c-4ca1-d27f-47b5a7ab423f"
   },
   "outputs": [],
   "source": [
    "# === Standard Library ===\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from random import sample\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "# === Scientific and Visualization Libraries ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import av\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# === PyTorch ===\n",
    "import torch\n",
    "\n",
    "# === Environment Tracking ===\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "# === Hugging Face Transformers ===\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    LlavaNextVideoForConditionalGeneration,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# === PEFT (Parameter-Efficient Fine-Tuning) ===\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model\n",
    ")\n",
    "\n",
    "# === Video Processing ===\n",
    "from decord import VideoReader, cpu\n",
    "\n",
    "# === Kaggle ===\n",
    "import kagglehub\n",
    "\n",
    "# === Datasets ===\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# === Federated Learning (Flower) ===\n",
    "import flwr as fl\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from flwr.client.mod import fixedclipping_mod\n",
    "from flwr.server.strategy import DifferentialPrivacyClientSideFixedClipping\n",
    "\n",
    "# === Custom Utilities ===\n",
    "from utils import *\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"codecarbon\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  name: DanJoshua/RWF-2000\n",
      "model:\n",
      "  name: llava-hf/LLaVa-NeXT-Video-7b-hf\n",
      "  quantization: 4\n",
      "  gradient_checkpointing: true\n",
      "  use_fast_tokenizer: false\n",
      "  lora:\n",
      "    r: 16\n",
      "    alpha: 64\n",
      "    target_modules:\n",
      "    - q_proj\n",
      "    - v_proj\n",
      "    dropout: 0.075\n",
      "    bias: none\n",
      "  num_frames: 24\n",
      "  save_model_path: fl_model/${model.name}_final_model.pt\n",
      "train:\n",
      "  num_rounds: ${flower.num_rounds}\n",
      "  save_every_round: 5\n",
      "  learning_rate_max: 5.0e-05\n",
      "  learning_rate_min: 1.0e-06\n",
      "  seq_length: 512\n",
      "  padding_side: left\n",
      "  evaluate_split: true\n",
      "  training_arguments:\n",
      "    batch_size: 2\n",
      "    output_dir: null\n",
      "    learning_rate: 5.0e-05\n",
      "    per_device_train_batch_size: 1\n",
      "    gradient_accumulation_steps: 1\n",
      "    logging_steps: 10\n",
      "    num_train_epochs: 3\n",
      "    max_steps: 10\n",
      "    report_to: null\n",
      "    save_steps: 1000\n",
      "    save_total_limit: 10\n",
      "    gradient_checkpointing: ${model.gradient_checkpointing}\n",
      "    lr_scheduler_type: constant\n",
      "flower:\n",
      "  num_clients: 4\n",
      "  num_rounds: 10\n",
      "  fraction_fit: 1.0e-05\n",
      "  min_fit_clients: 4\n",
      "  min_available_clients: 4\n",
      "  min_evaluate_clients: 4\n",
      "  client_resources:\n",
      "    num_cpus: 4\n",
      "    num_gpus: 1.0\n",
      "  dp:\n",
      "    noise_mult: 0.02\n",
      "    clip_norm: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = get_config(\"federated\")\n",
    "\n",
    "print_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /home/jovyan/.cache/kagglehub/datasets/yash07yadav/project-data/versions/1\n",
      "Saved 4 clients in data/clients_train/\n",
      "Saved 4 clients in data/clients_val/\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"yash07yadav/project-data\")\n",
    "print(f\"Dataset downloaded to: {path}\")    \n",
    "\n",
    "# Paths\n",
    "train_base_path = Path(path) / \"Complete Dataset\" / \"train\"\n",
    "val_base_path = Path(path) / \"Complete Dataset\" / \"val\"\n",
    "\n",
    "def load_video_paths(base_path, class_names=[\"NonFight\", \"Fight\"]):\n",
    "    \"\"\"Load video paths with labels from structured directory\"\"\"\n",
    "    dataset = {\"videos\": [], \"labels\": []}\n",
    "    \n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        # Verify download\n",
    "        class_dir = base_path / class_name\n",
    "        video_paths = list(class_dir.glob(\"*\"))\n",
    "        \n",
    "        for path in video_paths:\n",
    "            dataset[\"videos\"].append(str(path))\n",
    "            dataset[\"labels\"].append(label_idx)\n",
    "            \n",
    "    return Dataset.from_dict(dataset)\n",
    "    \n",
    "def partition_dataset(dataset: Dataset, num_clients: int = 4, seed: int = 42):\n",
    "    \"\"\"Split dataset into `num_clients` partitions.\"\"\"\n",
    "    random.seed(seed)\n",
    "    indices = list(range(len(dataset)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    partition_size = len(dataset) // num_clients\n",
    "    partitions = []\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        start = i * partition_size\n",
    "        end = start + partition_size if i != num_clients - 1 else len(dataset)\n",
    "        part_indices = indices[start:end]\n",
    "        partition = dataset.select(part_indices)\n",
    "        partitions.append(partition)\n",
    "\n",
    "    return partitions\n",
    "\n",
    "def save_partitions_to_dirs(partitions, save_base: str = \"data/clients\"):\n",
    "    \"\"\"Copy videos into data/clients/client_{i}/ folders.\"\"\"\n",
    "    for i, partition in enumerate(partitions):\n",
    "        client_dir = Path(save_base) / f\"client_{i}\"\n",
    "        client_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for video_path, label in zip(partition[\"videos\"], partition[\"labels\"]):\n",
    "            class_name = \"fight\" if label == 1 else \"nonfight\"\n",
    "            fname = f\"{class_name}_{os.path.basename(video_path)}\"\n",
    "            dst_path = client_dir / fname\n",
    "            shutil.copy(video_path, dst_path)\n",
    "\n",
    "    print(f\"Saved {len(partitions)} clients in {save_base}/\")\n",
    "\n",
    "# Example usage\n",
    "train_dataset = load_video_paths(train_base_path)\n",
    "val_dataset = load_video_paths(val_base_path)\n",
    "\n",
    "train_partitions = partition_dataset(train_dataset, num_clients=cfg.flower.num_clients)\n",
    "val_partitions = partition_dataset(val_dataset, num_clients=cfg.flower.num_clients)\n",
    "\n",
    "# ------------------- uncomment when number of clients changed -------------------------\n",
    "save_partitions_to_dirs(train_partitions, save_base=\"data/clients_train\")\n",
    "save_partitions_to_dirs(val_partitions, save_base=\"data/clients_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor, data_collator = get_processor_and_data_collator(\n",
    "    cfg.model.name,\n",
    "    cfg.model.use_fast_tokenizer,\n",
    "    cfg.train.padding_side,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./fl_model\"\n",
    "\n",
    "client = fl.client.ClientApp(\n",
    "    client_fn = gen_client_fn(\n",
    "        data_dir=\"data/clients_train\",\n",
    "        data_collator=data_collator,\n",
    "        model_cfg=cfg.model,\n",
    "        train_cfg=cfg.train.training_arguments,\n",
    "        save_path=save_path,\n",
    "    ),\n",
    "    mods=[fixedclipping_mod] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context):\n",
    "    # Define the Strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=cfg.flower.fraction_fit,\n",
    "        min_fit_clients=cfg.flower.min_fit_clients,\n",
    "        min_available_clients=cfg.flower.min_available_clients,\n",
    "        min_evaluate_clients=cfg.flower.min_evaluate_clients,\n",
    "\n",
    "        fraction_evaluate=0.0, # No federated evaluation\n",
    "        on_fit_config_fn=get_on_fit_config(cfg.flower.num_rounds),\n",
    "        fit_metrics_aggregation_fn=fit_weighted_average,\n",
    "        evaluate_fn=get_evaluate_fn(\n",
    "            cfg.model,\n",
    "            processor,\n",
    "            cfg.model.save_model_path,\n",
    "            val_base_path\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Add Differential Privacy\n",
    "    strategy = DifferentialPrivacyClientSideFixedClipping(\n",
    "        strategy, \n",
    "        noise_multiplier=cfg.flower.dp.noise_mult,\n",
    "        clipping_norm=cfg.flower.dp.clip_norm, \n",
    "        num_sampled_clients=cfg.flower.num_clients\n",
    "    )\n",
    "\n",
    "    # Number of rounds to run the simulation\n",
    "    config = fl.server.ServerConfig(\n",
    "        num_rounds=cfg.flower.num_rounds,\n",
    "    )\n",
    "    \n",
    "    return fl.server.ServerAppComponents(strategy=strategy, config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = fl.server.ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c8d586b7adc3490397ecf69ce43777f3",
      "401fe12988bc4eb596376d12650d0e33",
      "0f771a0911844597a7662467d433348c",
      "0eb6c4e383ed44a49c63b294d2497f08",
      "ce7835b817cd4256a9f43222ca5158cd",
      "73ae6bb487b34560bb233ef44ea89b08",
      "6f44cb4256e144f0883edc2f9a66553b",
      "075ff09c55024917a0741bb5ed02a934",
      "1e5c3668e5c240e2b561fee2e422742a",
      "2e7dc63fc9a04067a76326a629ba575d",
      "17f1844fc6cb43dd80dbac3b07474b23"
     ]
    },
    "id": "g6az6nYLaY5p",
    "outputId": "466eaa10-b64f-41de-d28c-5e48dd489fa8"
   },
   "outputs": [],
   "source": [
    "def run_simulation():\n",
    "    print(\"Starting federated training...\")\n",
    "\n",
    "    os.makedirs(f\"FedPer emissions/{cfg.model.name} Emissions\", exist_ok=True)\n",
    "\n",
    "    # Initialize trackers\n",
    "    emissions_tracker = EmissionsTracker(\n",
    "            project_name=f\"{cfg.model.name} FedPer Emissions\",\n",
    "            measure_power_secs=1,\n",
    "            output_dir=f\"FedPer emissions/{cfg.model.name} Emissions\",\n",
    "            save_to_file=True,\n",
    "            log_level=\"warning\"\n",
    "        )\n",
    "\n",
    "    emissions_tracker.start()\n",
    "\n",
    "    client_resources = dict(cfg.flower.client_resources)\n",
    "    fl.simulation.run_simulation(\n",
    "        server_app=server,\n",
    "        client_app=client,\n",
    "        num_supernodes=cfg.flower.num_clients,\n",
    "        backend_config={\"client_resources\": {\n",
    "                            \"num_cpus\": int(cfg.flower.client_resources[\"num_cpus\"]),\n",
    "                            \"num_gpus\": float(cfg.flower.client_resources[\"num_gpus\"]),\n",
    "                        },\n",
    "                        \"init_args\": backend_setup}\n",
    "    )\n",
    "\n",
    "    emissions_tracker.stop()\n",
    "\n",
    "    print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:05:04] Multiple instances of codecarbon are allowed to run at the same time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting federated training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:05:06] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon WARNING @ 05:05:06] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "\u001b[92mINFO \u001b[0m: Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [INIT]\n",
      "\u001b[92mINFO \u001b[0m: Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m: Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m: Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m: initial parameters (loss, other metrics): 0.0, {}\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (1, 0.0, {}, 221.67543571296846)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (2, 0.0, {}, 439.04576912900666)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (3, 0.0, {}, 662.4219730109908)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (4, 0.0, {}, 889.7956598119927)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (5, 0.0, {}, 1104.702892308007)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (6, 0.0, {}, 1329.0397601849982)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (7, 0.0, {}, 1553.8730544410064)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (8, 0.0, {}, 1776.1972141889855)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (9, 0.0, {}, 1998.8094422919676)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: central DP noise with 0.0025 stdev added\n",
      "\u001b[92mINFO \u001b[0m: fit progress: (10, 0.0, {}, 2231.6632742139627)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m: Run finished 10 round(s) in 2231.66s\n",
      "\u001b[92mINFO \u001b[0m: \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 0: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 1: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 2: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 3: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 4: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 5: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 6: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 7: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 8: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 9: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \t\tround 10: 0.0\n",
      "\u001b[92mINFO \u001b[0m: \tHistory (metrics, distributed, fit):\n",
      "\u001b[92mINFO \u001b[0m: \t{'train_loss': [(1, 14.556677028111048),\n",
      "\u001b[92mINFO \u001b[0m: \t                (2, 11.618792615618025),\n",
      "\u001b[92mINFO \u001b[0m: \t                (3, 7.795197187151228),\n",
      "\u001b[92mINFO \u001b[0m: \t                (4, 5.592363684517997),\n",
      "\u001b[92mINFO \u001b[0m: \t                (5, 4.6565101623535154),\n",
      "\u001b[92mINFO \u001b[0m: \t                (6, 4.383345849173409),\n",
      "\u001b[92mINFO \u001b[0m: \t                (7, 4.2571246010916575),\n",
      "\u001b[92mINFO \u001b[0m: \t                (8, 4.186683927263532),\n",
      "\u001b[92mINFO \u001b[0m: \t                (9, 4.128088051932199),\n",
      "\u001b[92mINFO \u001b[0m: \t                (10, 4.0827462877546035)]}\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "[codecarbon WARNING @ 05:42:48] Power history is empty, returning 0 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import Process\n",
    "    import time\n",
    "    import gc\n",
    "    \n",
    "    # Clear caches\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Run simulation\n",
    "    run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "075ff09c55024917a0741bb5ed02a934": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0eb6c4e383ed44a49c63b294d2497f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e7dc63fc9a04067a76326a629ba575d",
      "placeholder": "​",
      "style": "IPY_MODEL_17f1844fc6cb43dd80dbac3b07474b23",
      "value": " 0/3 [00:00&lt;?, ?it/s]"
     }
    },
    "0f771a0911844597a7662467d433348c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_075ff09c55024917a0741bb5ed02a934",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e5c3668e5c240e2b561fee2e422742a",
      "value": 0
     }
    },
    "17f1844fc6cb43dd80dbac3b07474b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e5c3668e5c240e2b561fee2e422742a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e7dc63fc9a04067a76326a629ba575d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "401fe12988bc4eb596376d12650d0e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73ae6bb487b34560bb233ef44ea89b08",
      "placeholder": "​",
      "style": "IPY_MODEL_6f44cb4256e144f0883edc2f9a66553b",
      "value": "Loading checkpoint shards:   0%"
     }
    },
    "6f44cb4256e144f0883edc2f9a66553b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73ae6bb487b34560bb233ef44ea89b08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8d586b7adc3490397ecf69ce43777f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_401fe12988bc4eb596376d12650d0e33",
       "IPY_MODEL_0f771a0911844597a7662467d433348c",
       "IPY_MODEL_0eb6c4e383ed44a49c63b294d2497f08"
      ],
      "layout": "IPY_MODEL_ce7835b817cd4256a9f43222ca5158cd"
     }
    },
    "ce7835b817cd4256a9f43222ca5158cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
